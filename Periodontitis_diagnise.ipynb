{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 4: Wenhan, Fengrui, Umair, Mimi\n",
    "\n",
    "Objective:\n",
    "Try to define probability for a patient to have a disease on their tooth supporting tissues from simple data that can be acquired remotely. It is to define the risk factors to develop such diseases.\n",
    "\n",
    "Features:\n",
    "\n",
    "ID\tID of the subject\n",
    "Sex\t\n",
    "Age\t\n",
    "BMI\tBody Mass Index\n",
    "Smoking\tSmoking consumption\n",
    "Pathologies\tSystemic diseases\n",
    "Pregnant\tYes/No\n",
    "Food_Sugar\tConsumption of sweet foods \n",
    "Fat_Salty\tConsumption of fatty or salty foods \n",
    "Soda\tConsumption of soda\n",
    "Alcohol\tConsumption of alcohol\n",
    "Frequence_Appoint_Dentist\tFrequency of Dental Surgeon Appointments\n",
    "Hygiene_Dental\tDental hygiene (number of brushing teeth a day)\n",
    "Gingivorrhagia\tGingival bleeding\n",
    "Stress_Daily\tIs the patient stressed (How many times he/she feels strees daily)\n",
    "PI\tDental plaque quantity\n",
    "Diagnosis\tPeriodontal diagnosis (to predict)\n",
    "\n",
    "ID\t1 - 248\n",
    "Sex\tMale/Femal\n",
    "Age\t0 - 80\n",
    "BMI\tBody Mass Index (weight/height^2)\n",
    "Smoking\t'Previous smoker''No smoker''Smoker'\n",
    "Pathologies\tYes/No\n",
    "Pregnant\tYes/No\n",
    "Food_Sugar\t'Never''Sometimes''Several times a week''Once a day''Several times a day'\n",
    "Fat_Salty\t'Never''Sometimes''Several times a week''Once a day''Several times a day'\n",
    "Soda\t'Never''Sometimes''Several times a week''Once a day''Several times a day'\n",
    "Alcohol\t'Never''Sometimes''Several times a week''Once a day''Several times a day'\n",
    "Frequence_Appoint_Dentist\t'Never''Once a year''2-3 a year''Regularly'\n",
    "Hygiene_Dental\t0 - 6\n",
    "Gingivorrhagia\t'Absent''Provoked''Spontanées''Corrélées (cycle, etc…)'\n",
    "Stress_Daily\t1 - 10\n",
    "PI\t0 - 3\n",
    "\n",
    "Labels:\n",
    "Diagnosis\t'Gingivitis''Periodontitis''Healthy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "def data_preprocess():\n",
    "    # Import dataset to panda data frame\n",
    "    data1 = pd.read_excel(\"/Users/ethanyang/Desktop/2IS/2IS-M12/Computational_Intelligence/data1.xlsx\")\n",
    "    pd.set_option('display.max_columns', 20)\n",
    "    del data1['Pregnant']\n",
    "    data1 = data1.dropna(axis=0, how='any')\n",
    "\n",
    "    # Convert string class to numerical class\n",
    "    data1['Sex'] = data1['Sex'].astype('category')\n",
    "    data1['Sex'] = data1['Sex'].cat.codes\n",
    "\n",
    "    # bins = [0, 20, 40, 60, 80]\n",
    "    # labels = [0, 1, 2, 3]\n",
    "    # data1['Age'] = pd.cut(data1['Age'], bins=bins, labels=labels, right=False)\n",
    "    # data1['Age'] = data1['Age'].astype(np.int8)\n",
    "    # print(data1['Age'])\n",
    "\n",
    "    # bins = [0, 10, 20, 30, 40, 50]\n",
    "    # labels = [0, 1, 2, 3, 4]\n",
    "    # data1['BMI'] = pd.cut(data1['BMI'], bins=bins, labels=labels, right=False)\n",
    "    # data1['BMI'] = data1['BMI'].astype(np.int8)\n",
    "    # print(data1['BMI'])\n",
    "\n",
    "    data1['Smoking'] = data1['Smoking'].astype('category')\n",
    "    data1['Smoking'] = data1['Smoking'].cat.codes\n",
    "    \n",
    "    data1['Pathologies'] = data1['Pathologies'].astype('category')\n",
    "    data1['Pathologies'] = data1['Pathologies'].cat.codes\n",
    "\n",
    "    # data1.Pregnant.fillna(1, inplace = True)\n",
    "    # list = data1[data1.Sex == 2].index.to_list()\n",
    "    # temp = data1.Pregnant\n",
    "    # print(temp)\n",
    "    # for i in list:\n",
    "    #     temp[i,:].fillna(1, inplace=True)\n",
    "    # print(temp)\n",
    "    # data1.Pregnant = data1[data1.Sex == 2]['Pregnant'].replace(np.nan, 1)\n",
    "    # data1[data1.Sex == 2].fillna({'Pregnant':1},inplace = True)\n",
    "    # fill = pd.Series(1, index = data1[data1.Sex == 2])\n",
    "    # print(fill)\n",
    "    # data1['Pregnant'].fillna(fill, inplace=True)\n",
    "    # print(data1[data1.Sex == 2]['Pregnant'])\n",
    "    # data1['Pregnant'] = data1['Pregnant'].astype('category')\n",
    "    # data1['Pregnant'] = data1['Pregnant'].cat.codes\n",
    "    # data1.Pregnant[data1.Pregnant == 'No'] = 1\n",
    "    # data1.Pregnant[data1.Pregnant == 'Yes'] = 2\n",
    "\n",
    "    data1['Food_Sugar'] = data1['Food_Sugar'].astype('category')\n",
    "    data1['Food_Sugar'] = data1['Food_Sugar'].cat.codes\n",
    "\n",
    "    data1['Fat_Salty'] = data1['Fat_Salty'].astype('category')\n",
    "    data1['Fat_Salty'] = data1['Fat_Salty'].cat.codes\n",
    "\n",
    "    data1['Soda'] = data1['Soda'].astype('category')\n",
    "    data1['Soda'] = data1['Soda'].cat.codes\n",
    "\n",
    "    data1['Alcohol'] = data1['Alcohol'].astype('category')\n",
    "    data1['Alcohol'] = data1['Alcohol'].cat.codes\n",
    "    \n",
    "    data1['Frequence_Appoint_Dentist'] = data1['Frequence_Appoint_Dentist'].astype('category')\n",
    "    data1['Frequence_Appoint_Dentist'] = data1['Frequence_Appoint_Dentist'].cat.codes\n",
    "\n",
    "    data1['Gingivorrhagia'] = data1['Gingivorrhagia'].astype('category')\n",
    "    data1['Gingivorrhagia'] = data1['Gingivorrhagia'].cat.codes\n",
    "\n",
    "    data1['Diagnosis'] = data1['Diagnosis'].astype('category')\n",
    "    data1['Diagnosis'] = data1['Diagnosis'].cat.codes\n",
    "\n",
    "    # print(data1.iloc[0:30,:])\n",
    "    # data1.info()\n",
    "    data1.iloc[:, 1:15] = (data1.iloc[:, 1:15] - data1.iloc[:, 1:15].min()) / (\n",
    "            data1.iloc[:, 1:15].max() - data1.iloc[:, 1:15].min())  # data normalization\n",
    "    # data1=(data1-data1.mean())/data1.std()\n",
    "    # print(data1.iloc[0:30, :])\n",
    "    return data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_correlation():\n",
    "    # Calculate the correlation\n",
    "    data = data_preprocess()\n",
    "    corr = data.corr()\n",
    "    print(corr)\n",
    "    sns.heatmap(corr, annot=True, fmt=\".1f\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_process():\n",
    "    # PCA\n",
    "    data = data_preprocess()\n",
    "    pca = PCA()\n",
    "    pca = PCA(n_components=1)\n",
    "    x_pca = data.loc[:, ['Age', 'BMI', 'Pathologies', 'Food_Sugar', 'Hygiene_Dental']]\n",
    "    # x_pca = data.iloc[:, 1:14]\n",
    "    y_pca = data.loc[:, ['Diagnosis']]\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(x_data, y_target, random_state=0, stratify=y_target)\n",
    "    pca.fit(x_pca)\n",
    "    X_train_pca = pca.transform(x_pca)\n",
    "    # X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # for X, y in zip((X_train_pca, X_test_pca), (y_train, y_test)):\n",
    "    #     for i, annot in enumerate(zip(('Gingivitis', 'Periodontitis', 'Healthy'),\n",
    "    #                                   ('blue', 'red', 'green'))):\n",
    "    #         plt.scatter(X[y==i, 0],\n",
    "    #                     X[y==i, 1],\n",
    "    #                     label=annot[0],\n",
    "    #                     c=annot[1])\n",
    "    #     plt.xlabel('Principal Component 1')\n",
    "    #     plt.ylabel('Principal Component 2')\n",
    "    #     plt.legend(loc='best')\n",
    "    #     plt.tight_layout()\n",
    "    #     plt.show()\n",
    "    return X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_select(i):\n",
    "    data = data_preprocess()\n",
    "    if i == 0:\n",
    "        x_data = data.iloc[:, 1:15]\n",
    "    if i == 1:\n",
    "        x_data = data.loc[:, ['Age', 'BMI', 'Pathologies', 'Food_Sugar', 'Hygiene_Dental']]   #use the correlated features\n",
    "    if i == 2:\n",
    "        x_data = pca_process()  # using data reduced dimension from PCA\n",
    "    if i == 3:\n",
    "        x_data = data.iloc[:, 2]  # use single feature\n",
    "        x_data = x_data.values.reshape(-1, 1)\n",
    "    y_data = data.loc[:, ['Diagnosis']]\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "def knn_process(i):\n",
    "    # KNN\n",
    "    x_data, y_data = data_select(i)\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "    #split validation\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.22, random_state=53)\n",
    "    knn.fit(X_train, np.ravel(Y_train, order='C'))\n",
    "    train_score = knn.score(X_train, Y_train)\n",
    "    test_score = knn.score(X_test, Y_test)\n",
    "    print('Train Acc: %.3f, Test Acc: %.3f' % (train_score, test_score))\n",
    "    #K-fold validation\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    results_kfold = model_selection.cross_val_score(knn, x_data, np.ravel(y_data, order='C'), cv=kfold)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_kfold.mean() * 100.0))\n",
    "    #leave one out validatoin\n",
    "    loocv = LeaveOneOut()\n",
    "    results_loocv = model_selection.cross_val_score(knn, x_data, np.ravel(y_data, order='C'), cv=loocv)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_loocv.mean() * 100.0))\n",
    "\n",
    "\n",
    "\n",
    "def decision_tree(i):\n",
    "    # Decision Tree\n",
    "    x_data, y_data = data_select(i)\n",
    "    Dt = DecisionTreeClassifier(max_depth=5)\n",
    "    #split validation\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.12, random_state=53)\n",
    "    Dt.fit(X_train, Y_train)\n",
    "    train_score = Dt.score(X_train, Y_train)\n",
    "    test_score = Dt.score(X_test, Y_test)\n",
    "    print('Train Acc: %.3f, Test Acc: %.3f' % (train_score, test_score))\n",
    "    #K-fold validation\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    results_kfold = model_selection.cross_val_score(Dt, x_data, np.ravel(y_data, order='C'), cv=kfold)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_kfold.mean() * 100.0))\n",
    "    #leave one out validatoin\n",
    "    loocv = LeaveOneOut()\n",
    "    results_loocv = model_selection.cross_val_score(Dt, x_data, np.ravel(y_data, order='C'), cv=loocv)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_loocv.mean() * 100.0))\n",
    "\n",
    "\n",
    "def support_vector(i):\n",
    "    x_data, y_data = data_select(i)\n",
    "    sv = SVC(kernel='linear', gamma=9, C=9)\n",
    "    #split validation\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=53)\n",
    "    sv.fit(X_train, np.ravel(Y_train, order='C'))\n",
    "    train_score = sv.score(X_train, Y_train)\n",
    "    test_score = sv.score(X_test, Y_test)\n",
    "    print('Train Acc: %.3f, Test Acc: %.3f' % (train_score, test_score))\n",
    "    # K-fold validation\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    results_kfold = model_selection.cross_val_score(sv, x_data, np.ravel(y_data, order='C'), cv=kfold)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_kfold.mean() * 100.0))\n",
    "    # leave one out validatoin\n",
    "    loocv = LeaveOneOut()\n",
    "    results_loocv = model_selection.cross_val_score(sv, x_data, np.ravel(y_data, order='C'), cv=loocv)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_loocv.mean() * 100.0))\n",
    "\n",
    "\n",
    "def neural_network(i):\n",
    "    x_data, y_data = data_select(i)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(4,2), solver='sgd',\n",
    "                        batch_size=4, learning_rate_init=0.005,\n",
    "                        max_iter=500, shuffle=True)\n",
    "    #split validation\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=53)\n",
    "    clf.fit(X_train, np.ravel(Y_train, order='C'))\n",
    "    print(\"Number of layers: \", clf.n_layers_)\n",
    "    print(\"Number of outputs: \", clf.n_outputs_)\n",
    "    train_score = clf.score(X_train, Y_train)\n",
    "    test_score = clf.score(X_test, Y_test)\n",
    "    print('Train Acc: %.3f, Test Acc: %.3f' % (train_score, test_score))\n",
    "    # K-fold validation\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    results_kfold = model_selection.cross_val_score(clf, x_data, np.ravel(y_data, order='C'), cv=kfold)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_kfold.mean() * 100.0))\n",
    "    # leave one out validatoin\n",
    "    loocv = LeaveOneOut()\n",
    "    results_loocv = model_selection.cross_val_score(clf, x_data, np.ravel(y_data, order='C'), cv=loocv)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_loocv.mean() * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_Classifier(i):\n",
    "    x_data, y_data = data_select(i)\n",
    "    gpc = GaussianProcessClassifier(random_state = 53)\n",
    "    # split validation\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=53)\n",
    "    gpc.fit(X_train, np.ravel(Y_train, order='C'))\n",
    "    train_score = gpc.score(X_train, Y_train)\n",
    "    test_score = gpc.score(X_test, Y_test)\n",
    "    print('Train Acc: %.3f, Test Acc: %.3f' % (train_score, test_score))\n",
    "    # K-fold validation\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    results_kfold = model_selection.cross_val_score(gpc, x_data, np.ravel(y_data, order='C'), cv=kfold)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_kfold.mean() * 100.0))\n",
    "    # leave one out validatoin\n",
    "    loocv = LeaveOneOut()\n",
    "    results_loocv = model_selection.cross_val_score(gpc, x_data, np.ravel(y_data, order='C'), cv=loocv)\n",
    "    print(\"Accuracy: %.2f%%\" % (results_loocv.mean() * 100.0))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # parameter 0: all the data except id\n",
    "    # parameter 1: 5 most correlated features\n",
    "    # parameter 2: data after pca process\n",
    "    # parameter 3: choose one feature\n",
    "\n",
    "    cal_correlation()\n",
    "    # knn_process(1)\n",
    "    # decision_tree(1)\n",
    "    # support_vector(1)\n",
    "    # neural_network(3)\n",
    "    # GP_Classifier(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
